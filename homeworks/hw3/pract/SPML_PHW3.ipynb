{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwUAmmTcl3G-"
      },
      "source": [
        "# SPML HW3: Breaking Defenses & Black-Box Attacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gThurMADlvnK"
      },
      "outputs": [],
      "source": [
        "name = 'Amir Mohammad Ezzati'\n",
        "std_id = '402212269'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wnLuXjkDmJWk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a030c33-28c8-402a-d097-f5574bc235ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, mobilenet_v2\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "\n",
        "from tqdm import trange, tqdm\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/SPML/'"
      ],
      "metadata": {
        "id": "iF7JXMaozS5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0246f9-7675-4aeb-b8b8-4e5b3165667f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YkpcqvmTcq6"
      },
      "source": [
        "# CIFAR10 Dataset (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSIlVGXMoQA6",
        "outputId": "9878c67c-a803-4b62-d98f-627bdc50122a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 31.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "norm_mean = (0.4914, 0.4822, 0.4465)\n",
        "norm_std = (0.2023, 0.1994, 0.2010)\n",
        "batch_size = 128\n",
        "\n",
        "mu = torch.tensor(norm_mean).view(3,1,1).to(device)\n",
        "std = torch.tensor(norm_std).view(3,1,1).to(device)\n",
        "\n",
        "# TODO: Set the upper limit and lower limit possible for images\n",
        "upper_limit = ((1 - mu) / std).view(3, 1, 1)\n",
        "lower_limit = ((0 - mu) / std).view(3, 1, 1)\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(norm_mean, norm_std)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(norm_mean, norm_std)\n",
        "])\n",
        "\n",
        "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainset), len(testset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA1WH2EyjTKO",
        "outputId": "18da392b-abcb-4597-f164-93d67b29edbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_3oDmJlmTD-"
      },
      "source": [
        "# Defensive Distillation (25 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cJsiRusm54S"
      },
      "source": [
        "[Defensive distillation](https://arxiv.org/abs/1511.04508) proceeds in four steps:\n",
        "\n",
        "1.   **Train the teacher network**, by setting the temperature of the softmax to T during the\n",
        "training phase.\n",
        "2.   **Compute soft labels** by apply the teacher network to each instance in the training set, again evaluating the softmax at temperature T.\n",
        "3.  **Train the distilled network** (a network with the same shape as the teacher network) on the soft labels, using softmax at temperature T.\n",
        "4.  Finally, when running the distilled network at test time to classify new inputs, use temperature 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppg_6w0joa-D"
      },
      "source": [
        "## Train the teacher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZj3ygtFocYN"
      },
      "outputs": [],
      "source": [
        "def train_step(model, dataloader, loss_fn, optimizer, temperature):\n",
        "    # TODO: Return loss and accuracy for each epoch\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs / temperature  # Apply temperature scaling to logits\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def train_teacher(model, n_epochs, loader=trainloader, temp=100):\n",
        "    # TODO: Log the accuracy and loss for each epoch\n",
        "    model.to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        loss, acc = train_step(model, loader, loss_fn, optimizer, temp)\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs} - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evuzvOUZ4bPT"
      },
      "source": [
        "You can use a pre-trained resnet to speed up the training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_oKlYe7m4w-",
        "outputId": "f24126fe-3e7f-454f-f1bc-5a7faa4b47b7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 164MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15 - Loss: 1.3704, Accuracy: 0.6797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/15 - Loss: 0.6588, Accuracy: 0.7917\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/15 - Loss: 0.4649, Accuracy: 0.8507\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/15 - Loss: 0.3493, Accuracy: 0.8882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/15 - Loss: 0.2555, Accuracy: 0.9179\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/15 - Loss: 0.1972, Accuracy: 0.9368\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/15 - Loss: 0.1439, Accuracy: 0.9554\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/15 - Loss: 0.1172, Accuracy: 0.9625\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/15 - Loss: 0.1002, Accuracy: 0.9684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/15 - Loss: 0.0790, Accuracy: 0.9743\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/15 - Loss: 0.0724, Accuracy: 0.9768\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/15 - Loss: 0.0650, Accuracy: 0.9789\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/15 - Loss: 0.0576, Accuracy: 0.9815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/15 - Loss: 0.0496, Accuracy: 0.9842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15 - Loss: 0.0540, Accuracy: 0.9821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "teacher = resnet18(pretrained=True)\n",
        "teacher.fc = nn.Linear(teacher.fc.in_features, 10)\n",
        "\n",
        "train_teacher(teacher, 15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"teacher_pretrained_resnet18_15epochs.pth\"\n",
        "model_PATH = base_path + f\"{model_name}\"\n",
        "torch.save(teacher.state_dict(), model_PATH)"
      ],
      "metadata": {
        "id": "NZKFuNHmxyWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EFhPyAmzmeB"
      },
      "source": [
        "## Test the teacher"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = resnet18(pretrained=False)\n",
        "teacher.fc = nn.Linear(teacher.fc.in_features, 10)\n",
        "teacher = teacher.to(device)\n",
        "teacher.load_state_dict(torch.load(base_path + \"teacher_pretrained_resnet18_15epochs.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx6RMOAR2wCT",
        "outputId": "fce0c51e-3145-4079-969d-45f3ceecfb91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-5b2721e73c07>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  teacher.load_state_dict(torch.load(base_path + \"teacher_pretrained_resnet18_15epochs.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iIVtvL32zopl"
      },
      "outputs": [],
      "source": [
        "def test_clean(model, dataloader=testloader):\n",
        "    # TODO: Return the clean accuracy of the model\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(dataloader, desc=\"Testing\", leave=False):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs9LVS7uN-Fp"
      },
      "source": [
        "Print the clean accuracy of the teacher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFEzA16Cz63A",
        "outputId": "3bdbd02d-f315-44e5-e4f2-f7b020b7cba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Accuracy 81.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(f'Teacher Accuracy {test_clean(teacher):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68Fnkb39vYnl"
      },
      "source": [
        "## Train the student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfu9ZVWFvaL5"
      },
      "outputs": [],
      "source": [
        "def distill(model, teacher, dataloader, optimizer, T):\n",
        "    # TODO: Get soft labels from teacher model\n",
        "    # TODO: Get student model outputs\n",
        "    # TODO: Compute the distillation loss\n",
        "    # TODO: Return the accuracy (on real labels) and loss (on soft labels)\n",
        "\n",
        "    model.train()\n",
        "    teacher.eval()\n",
        "    loss_fn = nn.KLDivLoss(reduction='batchmean')  # KL divergence for soft labels\n",
        "\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in tqdm(dataloader, desc=\"Distillation Training\", leave=False):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs = teacher(inputs) / T\n",
        "        student_outputs = model(inputs) / T  # Apply temperature scaling to both logits\n",
        "\n",
        "        teacher_probs = F.softmax(teacher_outputs, dim=1)\n",
        "        student_log_probs = F.log_softmax(student_outputs, dim=1)\n",
        "\n",
        "        distill_loss = loss_fn(student_log_probs, teacher_probs) * (T**2)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        distill_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += distill_loss.item()\n",
        "\n",
        "        _, predicted = (student_outputs * T).max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_acc, epoch_loss\n",
        "\n",
        "\n",
        "def train_student(model, teacher, n_epochs, loader=trainloader, temp=100):\n",
        "    # TODO: Log the accuracy and loss for each epoch\n",
        "    model.to(device)\n",
        "    teacher.to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        acc, loss = distill(model, teacher, loader, optimizer, temp)\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs} - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80y5gpfCIJjW"
      },
      "source": [
        "This time use a `resnet18` without the pretrained weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhSefyQRwcFK",
        "outputId": "f5a53d2a-754b-4843-fc7d-ec0ebccb86fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Loss: 15363.2048, Accuracy: 0.4780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Loss: 9921.0126, Accuracy: 0.6413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Loss: 7770.4345, Accuracy: 0.7185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Loss: 6329.2704, Accuracy: 0.7675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Loss: 5238.1133, Accuracy: 0.8086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Loss: 4242.9113, Accuracy: 0.8449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Loss: 3384.1316, Accuracy: 0.8755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Loss: 2710.7089, Accuracy: 0.9000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Loss: 2119.9015, Accuracy: 0.9206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Loss: 1658.0158, Accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Loss: 1360.9280, Accuracy: 0.9495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Loss: 1060.2816, Accuracy: 0.9601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Loss: 1006.6803, Accuracy: 0.9619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Loss: 915.4780, Accuracy: 0.9649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Loss: 869.4710, Accuracy: 0.9664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Loss: 796.1015, Accuracy: 0.9695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Loss: 695.7563, Accuracy: 0.9718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Loss: 697.4539, Accuracy: 0.9733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - Loss: 644.4445, Accuracy: 0.9740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - Loss: 605.4570, Accuracy: 0.9758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - Loss: 636.2325, Accuracy: 0.9741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - Loss: 587.2774, Accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 - Loss: 587.2548, Accuracy: 0.9771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 - Loss: 540.9039, Accuracy: 0.9781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 - Loss: 554.4584, Accuracy: 0.9771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 - Loss: 547.2722, Accuracy: 0.9777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30 - Loss: 531.4476, Accuracy: 0.9779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30 - Loss: 505.4493, Accuracy: 0.9794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30 - Loss: 433.5928, Accuracy: 0.9815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30 - Loss: 485.8684, Accuracy: 0.9796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "student = resnet18(pretrained=False)\n",
        "student.fc = nn.Linear(student.fc.in_features, 10)\n",
        "\n",
        "train_student(student, teacher, 30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"student_fromscratch_resnet18_30epochs.pth\"\n",
        "model_PATH = base_path + f\"{model_name}\"\n",
        "torch.save(student.state_dict(), model_PATH)"
      ],
      "metadata": {
        "id": "9itUmaCy2Qjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snQvAMfH4ku1"
      },
      "source": [
        "## Test the student"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student = resnet18(pretrained=False)\n",
        "student.fc = nn.Linear(student.fc.in_features, 10)\n",
        "student = student.to(device)\n",
        "student.load_state_dict(torch.load(base_path + \"student_fromscratch_resnet18_30epochs.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_XXaDfj5LW2",
        "outputId": "b9fcdd3b-1a49-4cf0-b86a-d6cf5e77d05d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-36-69de5d57f4f9>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  student.load_state_dict(torch.load(base_path + \"student_fromscratch_resnet18_30epochs.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "D_phh7vc4pA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0840a398-1d1d-49a2-fafe-76d31c8a9f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Accuracy 77.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(f'Student Accuracy {test_clean(student):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdUmJKwtw-Gj"
      },
      "source": [
        "# Attack (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_-PnbtU3Zo1"
      },
      "source": [
        "Implement the FGSM attack and the `test_attack` funcion to report the robust accuracy for different values of epsilon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "axKc8-GExDh1"
      },
      "outputs": [],
      "source": [
        "def attack_fgsm(model, x, y, epsilon, temp):\n",
        "    # TODO: Return perturbed input\n",
        "    ce = CrossEntropyLoss()\n",
        "    x_adv = x.clone().detach().requires_grad_(True)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.enable_grad():\n",
        "        outputs = model(x_adv) / temp\n",
        "        loss_ = ce(outputs, y)\n",
        "        loss_.backward()\n",
        "\n",
        "        x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
        "        x_adv = torch.clamp(x_adv, lower_limit, upper_limit) # Clip to valid range\n",
        "\n",
        "    return x_adv.detach()\n",
        "\n",
        "def attack_pgd(model, x, y, epsilon, temp, alpha=0.2, num_iters=10):\n",
        "    # TODO: Return perturbed input\n",
        "\n",
        "    ce = CrossEntropyLoss()\n",
        "    x_adv = x.clone().detach().to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for _ in range(num_iters):\n",
        "        x_adv.requires_grad_(True)\n",
        "        # model.zero_grad()\n",
        "\n",
        "        outputs = model(x_adv) / temp\n",
        "        loss = ce(outputs, y)\n",
        "        loss.backward()\n",
        "\n",
        "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
        "\n",
        "        # Project back to epsilon-ball around x\n",
        "        perturbation = torch.clamp(x_adv - x, -epsilon, epsilon)\n",
        "        x_adv = torch.clamp(x + perturbation, lower_limit, upper_limit).detach().requires_grad_(True)\n",
        "\n",
        "    return x_adv.detach()\n",
        "\n",
        "\n",
        "def test_attack(model, epsilon, temp=100, attack=attack_fgsm, loader=testloader):\n",
        "    # TODO: Return the robust accuracy for FGSM or PGD\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in tqdm(loader, desc=f\"Testing attack (epsilon={epsilon})\", leave=False):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        inputs_adv = attack(model, inputs, targets, epsilon, temp)\n",
        "\n",
        "        # Evaluate the model on adversarial examples\n",
        "        outputs = model(inputs_adv)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    robust_accuracy = 100.0 * correct / total\n",
        "    return robust_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqUrHA1D1Oqk"
      },
      "source": [
        "Report the robust accuracy of the teacher for `ϵ = [1, 2, 4, 8, 16]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HMqzS21002f",
        "outputId": "d72bc544-b484-4e25-951a-b05a2cedbfdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=1/255 has Accuracy: 74.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=1/255 has Accuracy: 74.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=2/255 has Accuracy: 68.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=2/255 has Accuracy: 67.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=4/255 has Accuracy: 55.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=4/255 has Accuracy: 54.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=8/255 has Accuracy: 38.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=8/255 has Accuracy: 34.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=16/255 has Accuracy: 20.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=16/255 has Accuracy: 15.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "epsilons = [1, 2, 4, 8, 16]\n",
        "\n",
        "for eps in epsilons:\n",
        "    # TODO:\n",
        "    acc = test_attack(teacher, eps/255, attack=attack_fgsm, temp=100)\n",
        "    print(f'FGSM with ϵ={eps}/255 has Accuracy: {acc:.2f}%')\n",
        "\n",
        "    acc = test_attack(teacher, eps/255, attack=attack_pgd, temp=100)\n",
        "    print(f'PGD  with ϵ={eps}/255 has Accuracy: {acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd0E5Lrf3wyU"
      },
      "source": [
        "Do the same for the student:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn0oMzvk3wZR",
        "outputId": "2a90d704-fbef-41c6-bae3-868a79e04e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=1/255 has Accuracy: 73.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=1/255 has Accuracy: 73.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=2/255 has Accuracy: 73.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=2/255 has Accuracy: 73.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=4/255 has Accuracy: 73.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=4/255 has Accuracy: 73.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=8/255 has Accuracy: 73.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=8/255 has Accuracy: 73.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=16/255 has Accuracy: 73.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=16/255 has Accuracy: 73.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "for eps in epsilons:\n",
        "    # TODO:\n",
        "    acc = test_attack(student, eps/255, attack=attack_fgsm, temp=1)\n",
        "    print(f'FGSM with ϵ={eps}/255 has Accuracy: {acc:.2f}%')\n",
        "\n",
        "    acc = test_attack(student, eps/255, attack=attack_pgd, temp=1)\n",
        "    print(f'PGD  with ϵ={eps}/255 has Accuracy: {acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgHqlsaa33j1"
      },
      "source": [
        "What do you see?\n",
        "\n",
        "`your response:`\n",
        "\n",
        "The teacher model's accuracy drops significantly as ϵ increases, showing vulnerability to adversarial attacks (e.g., 74% at ϵ=1/255 to ~15% at ϵ=16/255). PGD is slightly stronger than FGSM, highlighting its iterative effectiveness.\n",
        "\n",
        "In contrast, the student model maintains stable accuracy (~73.5%) across all ϵ values, demonstrating strong robustness due to defensive distillation. This robustness arises because the student model, trained with a high temperature (T=100) and evaluated at T=1, exhibits higher confidence in its predictions. This high confidence causes gradients to approach zero, making adversarial perturbations (from FGSM and PGD) ineffective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFbxKpeM4AR9"
      },
      "source": [
        "# Transferring Adversarial Examples (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Vu8xSsLeqN"
      },
      "source": [
        "Train yet another model to be used as the surrogate. (set temperature to 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qBouBbUKHoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa645c7-794a-4cd6-8ce2-36857571300f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 391/391 [00:22<00:00, 17.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15, Loss: 1.3603, Accuracy: 51.05%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:19<00:00, 19.91it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/15, Loss: 0.9665, Accuracy: 65.78%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [00:17<00:00, 21.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/15, Loss: 0.7888, Accuracy: 72.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:17<00:00, 21.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15, Loss: 0.6563, Accuracy: 77.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:19<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15, Loss: 0.5556, Accuracy: 80.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:18<00:00, 21.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15, Loss: 0.4545, Accuracy: 84.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:19<00:00, 19.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15, Loss: 0.3795, Accuracy: 86.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:18<00:00, 21.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15, Loss: 0.3031, Accuracy: 89.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:19<00:00, 20.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15, Loss: 0.2442, Accuracy: 91.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:18<00:00, 21.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15, Loss: 0.1997, Accuracy: 92.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:18<00:00, 21.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15, Loss: 0.1669, Accuracy: 94.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:18<00:00, 20.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15, Loss: 0.1377, Accuracy: 95.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:19<00:00, 20.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15, Loss: 0.1157, Accuracy: 95.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:18<00:00, 21.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15, Loss: 0.1081, Accuracy: 96.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:18<00:00, 20.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15, Loss: 0.1000, Accuracy: 96.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "def train_surrogate(model, dataloader, epochs=15):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss, correct, total = 0, 0, 0\n",
        "        for x, y in tqdm(dataloader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            pred = outputs.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "train_surrogate(model, trainloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"surrogate_model.pth\"\n",
        "model_PATH = base_path + f\"{model_name}\"\n",
        "torch.save(model.state_dict(), model_PATH)"
      ],
      "metadata": {
        "id": "BZu3GMnd-71E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WBJtNiyL8WP"
      },
      "source": [
        "Print the surrogate accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(base_path + \"surrogate_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBm0A-Ge-7RR",
        "outputId": "18b2168a-dc50-463f-8063-2476332f4bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-13-fe733a050aa6>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(base_path + \"surrogate_model.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdgr2I-VMCi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898cc370-74fc-46b1-a8b6-6ca92b4c1bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy 76.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(f'Model Accuracy {test_clean(model):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcMBV3o6MC47"
      },
      "source": [
        "Report the accuracy of the surrogate for `ϵ = [1, 2, 4, 8, 16]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EALFUBHpMLdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc11b3a-d854-4c92-8503-f63950826036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=1/255 has Accuracy: 71.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=1/255 has Accuracy: 71.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=2/255 has Accuracy: 67.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=2/255 has Accuracy: 67.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=4/255 has Accuracy: 58.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=4/255 has Accuracy: 57.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=8/255 has Accuracy: 43.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=8/255 has Accuracy: 41.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=16/255 has Accuracy: 22.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD  with ϵ=16/255 has Accuracy: 19.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "epsilons = [1, 2, 4, 8, 16]\n",
        "\n",
        "for eps in epsilons:\n",
        "    # TODO:\n",
        "    acc = test_attack(model, eps/255, attack=attack_fgsm, temp=1)\n",
        "    print(f'FGSM with ϵ={eps}/255 has Accuracy: {acc:.2f}%')\n",
        "\n",
        "    acc = test_attack(model, eps/255, attack=attack_pgd, temp=1)\n",
        "    print(f'PGD  with ϵ={eps}/255 has Accuracy: {acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buQG6pvgLsAc"
      },
      "source": [
        "Implement the following functions to transfer attacks from a surrogate model to an oracle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu2vy0kY5Rmi"
      },
      "outputs": [],
      "source": [
        "def transfer_attack(oracle, model, eps, loader=testloader):\n",
        "    # TODO: Attack the model and report the accuracy of the oracle\n",
        "    oracle.eval()\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for x, y in tqdm(loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # Generate adversarial examples using the surrogate\n",
        "        x_adv = attack_fgsm(model, x, y, eps, temp=1)  # or use attack_pgd\n",
        "\n",
        "        # Evaluate the oracle on these adversarial examples\n",
        "        with torch.no_grad():\n",
        "            outputs = oracle(x_adv)\n",
        "            pred = outputs.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return 100 * correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO24bT2p6oyl"
      },
      "source": [
        "Transfer attacks for `ϵ = [1, 2, 4, 8, 16]` from your model to the student."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfcu7QgD6vtW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c0f685-a1e6-4900-ac8d-278ba92279ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:03<00:00, 21.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=1/255 has Accuracy: 76.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:04<00:00, 16.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=2/255 has Accuracy: 75.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:04<00:00, 18.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=4/255 has Accuracy: 73.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:03<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=8/255 has Accuracy: 70.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:03<00:00, 22.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=16/255 has Accuracy: 63.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epsilons = [1, 2, 4, 8, 16]\n",
        "\n",
        "for eps in epsilons:\n",
        "    acc = transfer_attack(student, model, eps/255)\n",
        "    print(f'FGSM with ϵ={eps}/255 has Accuracy: {acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtGOcOmzPO3G"
      },
      "source": [
        "- What can be inferred from these results?\n",
        "\n",
        "- How are the accuracies of the student and the surrogate under attack related?\n",
        "\n",
        "- Does Defensive Distillation obfuscate the gradients? Why?\n",
        "\n",
        "\n",
        "`your response:`\n",
        "\n",
        "- The student model shows robustness to direct attacks but is vulnerable to surrogate-generated adversarial examples as the accuracy drops significantly with increasing ε. This result demonstrates that the student's robustness to adversarial examples is fake, as it fails to generalize against transferable adversarial attacks.\n",
        "\n",
        "- Both the surrogate and student models' accuracies drop as ε increases, indicating that a more successful attack on the surrogate model is likely to transfer more effectively to the student model. However, the accuracy drop in the surrogate is more significant than in the student because the attack is applied directly to the surrogate, while the student model only experiences the transferred adversarial examples.\n",
        "\n",
        "- Yes, defensive distillation obfuscates the gradients. The high confidence of the student model (due to T=100 during training and T=1 during test) results in smoother gradients, reducing the impact of direct FGSM and PGD attacks. However, adversarial examples generated from a surrogate exploit transferability, bypassing this obfuscation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRPjp84p81nn"
      },
      "source": [
        "# ZOO Based Black-Box Attacks (25 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aaXmYSbQ2W_"
      },
      "source": [
        "Based on [Black-box Adversarial Attacks with Limited Queries and Information](https://arxiv.org/abs/1804.08598) you must first calculate the estimate of the gradients, and next attack the model based on your estimates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6PlkF_A-aDS"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "def nes_gradient_estimate(model, x, y, epsilon, num_samples, sigma):\n",
        "    # TODO: Return the estimated gradient\n",
        "    grad_estimate = torch.zeros_like(x).to(x.device)\n",
        "    model.eval()\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        u = torch.randn_like(x).to(x.device)\n",
        "        perturbed_plus = torch.clamp(x + sigma * u, lower_limit, upper_limit)\n",
        "        perturbed_minus = torch.clamp(x - sigma * u, lower_limit, upper_limit)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loss_plus = cross_entropy(model(perturbed_plus), y, reduction='none')\n",
        "            loss_minus = cross_entropy(model(perturbed_minus), y, reduction='none')\n",
        "\n",
        "        grad_estimate += (loss_plus - loss_minus).view(-1, 1, 1, 1) * u\n",
        "\n",
        "    grad_estimate /= (2 * num_samples * sigma)\n",
        "    return grad_estimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBF7Spoh-nmJ"
      },
      "outputs": [],
      "source": [
        "def partial_information_attack(model, x, y, epsilon, num_samples, sigma, num_steps, alpha):\n",
        "    # TODO: Return the perturbed image\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(x.device)\n",
        "    model.eval()\n",
        "\n",
        "    for _ in range(num_steps):\n",
        "        # Estimate the gradient using NES\n",
        "        grad_estimate = nes_gradient_estimate(model, x_adv, y, epsilon, num_samples, sigma)\n",
        "\n",
        "        # Update the adversarial image\n",
        "        x_adv = x_adv + alpha * grad_estimate.sign()\n",
        "\n",
        "        x_adv = torch.clamp(x_adv, x - epsilon, x + epsilon)\n",
        "        x_adv = torch.clamp(x_adv, lower_limit, upper_limit)  # Ensure valid pixel range\n",
        "\n",
        "    return x_adv.detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8XgGVWZRb1P"
      },
      "source": [
        "Now run this attack on your models and report the results. (You **DON'T** need to run the attack for the entire test dataset as this will take a lot of time!)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def partial_information_attack_batch(model, x, y, epsilon, num_samples, sigma, num_steps, alpha):\n",
        "  batch_size = x.shape[0]\n",
        "  x_adv_batch = []\n",
        "\n",
        "  for i in range(batch_size):\n",
        "      x_i = x[i:i+1]\n",
        "      y_i = y[i:i+1]\n",
        "\n",
        "      x_adv_i = partial_information_attack(model, x_i, y_i, epsilon, num_samples, sigma, num_steps, alpha)\n",
        "      x_adv_batch.append(x_adv_i)\n",
        "\n",
        "  x_adv_batch = torch.cat(x_adv_batch, dim=0)\n",
        "  return x_adv_batch\n"
      ],
      "metadata": {
        "id": "m2wi4lwyOw3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 16 / 255\n",
        "num_samples = 500\n",
        "sigma = 0.1\n",
        "num_steps = 3\n",
        "alpha = 0.2\n",
        "\n",
        "test_samples = next(iter(testloader))\n",
        "x_test, y_test = test_samples[0][:50].to(device), test_samples[1][:50].to(device)\n",
        "\n",
        "# Perform the attack on the teacher and student models\n",
        "x_adv_teacher = partial_information_attack_batch(teacher, x_test, y_test, epsilon, num_samples, sigma, num_steps, alpha)\n",
        "x_adv_student = partial_information_attack_batch(student, x_test, y_test, epsilon, num_samples, sigma, num_steps, alpha)"
      ],
      "metadata": {
        "id": "-gqFf8rOjZEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the accuracy of the models on adversarial examples\n",
        "with torch.no_grad():\n",
        "    teacher_acc = (teacher(x_adv_teacher).argmax(1) == y_test).sum().item()/y_test.size(0) * 100\n",
        "    student_acc = (student(x_adv_student).argmax(1) == y_test).sum().item()/y_test.size(0) * 100\n",
        "\n",
        "print(f\"Teacher Model Robust Accuracy under ZOO Attack: {teacher_acc:.2f}%\")\n",
        "print(f\"Student Model Robust Accuracy under ZOO Attack: {student_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1D20ehofx__",
        "outputId": "96f9e98c-8843-4730-dbd6-face5b317990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model Robust Accuracy under ZOO Attack: 68.00%\n",
            "Student Model Robust Accuracy under ZOO Attack: 78.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P30qgaIHVFxr"
      },
      "source": [
        "# Adversarially Robust Distillation (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlP5yndiV7Fg"
      },
      "source": [
        "In this section we are going to test another type of distillation to see if this method is robust. This technique is [Adversarially Robust Distillation](https://arxiv.org/abs/1905.09747).\n",
        "\n",
        "\n",
        "\n",
        "1.   We will try to distill a robsut teacher from [Robust Bench](https://robustbench.github.io/) onto a smaller architecture.\n",
        "2.   We minimize the KL-Divergence between the logits of the student and teacher to ensure fidelity. (You can also incorporate the classification loss as mentioned in the paper but you can choose to ignore it as well)\n",
        "3.   At each step of the distillation you will attack the student (you can use either FGSM or PGD) and find an adversarial example $X + \\delta$ for data point $X$. Next you will minimize $t^2 \\times \\text{KL}(S(X+\\delta), T(X))$ where $S$ and $T$ are the student and teacher networks respectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kOHVJtf0V6NT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c1e338-b829-4b2a-80f1-06d9264a73c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for robustbench (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for autoattack (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/RobustBench/robustbench.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "upper_limit = torch.tensor([1, 1, 1]).view(3, 1, 1).to(device)\n",
        "lower_limit = torch.tensor([0, 0, 0]).view(3, 1, 1).to(device)\n",
        "\n",
        "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "train_dataloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "test_dataloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YLN8iho5E9q",
        "outputId": "6e844e2d-11ce-4ac6-9d49-441a672e3160"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nD9wjBojWz_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98684a3-42b8-4532-c73d-2daea6aae530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models/cifar10/Linf/Gowal2021Improving_R18_ddpm_100m.pt (gdrive_id=1-0EuCJashqSXEkkd1DOzFA4tH8KL2kim).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-0EuCJashqSXEkkd1DOzFA4tH8KL2kim\n",
            "From (redirected): https://drive.google.com/uc?id=1-0EuCJashqSXEkkd1DOzFA4tH8KL2kim&confirm=t&uuid=f62da137-eeba-4932-94c4-b0be15c0ed0e\n",
            "To: /content/models/cifar10/Linf/Gowal2021Improving_R18_ddpm_100m.pt\n",
            "100%|██████████| 50.3M/50.3M [00:01<00:00, 49.0MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/robustbench/utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
          ]
        }
      ],
      "source": [
        "from robustbench.utils import load_model\n",
        "\n",
        "teacher = load_model(model_name='Gowal2021Improving_R18_ddpm_100m', dataset='cifar10', threat_model='Linf')\n",
        "teacher = teacher.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean accurcy\n",
        "print(f'Teacher Clean Accuracy {test_clean(teacher, dataloader=test_dataloader):.2f}%')\n",
        "\n",
        "# FGSM with eps=8/255\n",
        "acc = test_attack(teacher, 8/255, attack=attack_fgsm, loader=test_dataloader, temp=1)\n",
        "print(f'FGSM with ϵ=8/255 has Accuracy: {acc:.2f}%')\n",
        "\n",
        "# PGD with eps=8/255\n",
        "acc = test_attack(teacher, 8/255, attack=attack_pgd, loader=test_dataloader, temp=1)\n",
        "print(f'PGD with ϵ=8/255 has Accuracy: {acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEIXMMIK3faB",
        "outputId": "3da463b0-3319-48de-db2e-b48991bd037b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Clean Accuracy 87.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=8/255 has Accuracy: 66.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD with ϵ=8/255 has Accuracy: 62.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FLGDeE1YY6uO"
      },
      "outputs": [],
      "source": [
        "def ard(student, teacher, dataloader, optimizer, eps, attack, t):\n",
        "    # TODO\n",
        "    KL_loss = nn.KLDivLoss()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        if attack == 'FGSM':\n",
        "            x_adv = attack_fgsm(student, x, y, epsilon=eps, temp=t)\n",
        "        elif attack == 'PGD':\n",
        "            x_adv = attack_pgd(student, x, y, epsilon=eps, temp=t)\n",
        "\n",
        "        student.train()\n",
        "\n",
        "        student_logits = student(x_adv) / t\n",
        "        teacher_logits = teacher(x) / t\n",
        "\n",
        "        # Compute the distillation loss (KL divergence)\n",
        "        kl_loss = KL_loss(F.log_softmax(student_logits, dim=1),\n",
        "                          F.softmax(teacher_logits, dim=1)) * (t**2)\n",
        "\n",
        "        loss = kl_loss #+ ce_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predicted = student(x).max(1)\n",
        "        correct += predicted.eq(y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    accuracy = correct / total\n",
        "    return average_loss, accuracy\n",
        "\n",
        "\n",
        "def adv_train_student(model, teacher, n_epochs, eps=8/255, temp=1, loader=train_dataloader):\n",
        "    # TODO\n",
        "    model.train()\n",
        "    teacher.eval()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        loss, acc = ard(model, teacher, loader, optimizer, eps, attack='FGSM', t=temp)\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs} - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eAEyoDc-ZUtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1aa595-3cc0-4701-cb12-51b4a673b1d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3369: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 - Loss: 0.2038, Accuracy: 0.1529\n",
            "Epoch 2/15 - Loss: 0.1800, Accuracy: 0.2334\n",
            "Epoch 3/15 - Loss: 0.1736, Accuracy: 0.2657\n",
            "Epoch 4/15 - Loss: 0.1703, Accuracy: 0.2744\n",
            "Epoch 5/15 - Loss: 0.1665, Accuracy: 0.2965\n",
            "Epoch 6/15 - Loss: 0.1637, Accuracy: 0.3105\n",
            "Epoch 7/15 - Loss: 0.1605, Accuracy: 0.3357\n",
            "Epoch 8/15 - Loss: 0.1582, Accuracy: 0.3653\n",
            "Epoch 9/15 - Loss: 0.1556, Accuracy: 0.3809\n",
            "Epoch 10/15 - Loss: 0.1536, Accuracy: 0.3922\n",
            "Epoch 11/15 - Loss: 0.1525, Accuracy: 0.4044\n",
            "Epoch 12/15 - Loss: 0.1505, Accuracy: 0.4191\n",
            "Epoch 13/15 - Loss: 0.1490, Accuracy: 0.4292\n",
            "Epoch 14/15 - Loss: 0.1480, Accuracy: 0.4409\n",
            "Epoch 15/15 - Loss: 0.1467, Accuracy: 0.4456\n"
          ]
        }
      ],
      "source": [
        "student = mobilenet_v2(weights=None, num_classes=10)\n",
        "student = student.to(device)\n",
        "\n",
        "temperature = 1\n",
        "# TODO: Adjust and train the student\n",
        "adv_train_student(student, teacher, n_epochs=15, temp=temperature, loader=train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwVcIMu9ZF12"
      },
      "source": [
        "Now report the accuracy of the student on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "6_tXDzGyZNCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f9a25e-7f6e-4e57-cfb3-12d37f003bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Clean Accuracy 43.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM with ϵ=8/255 has Accuracy: 31.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD with ϵ=8/255 has Accuracy: 30.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# TODO: Clean accurcy\n",
        "print(f'Student Clean Accuracy {test_clean(student, dataloader=test_dataloader):.2f}%')\n",
        "\n",
        "# TODO: FGSM with eps=8/255\n",
        "acc = test_attack(student, 8/255, attack=attack_fgsm, loader=test_dataloader, temp=1)\n",
        "print(f'FGSM with ϵ=8/255 has Accuracy: {acc:.2f}%')\n",
        "\n",
        "# TODO: PGD with eps=8/255\n",
        "acc = test_attack(student, 8/255, attack=attack_pgd, loader=test_dataloader, temp=1)\n",
        "print(f'PGD with ϵ=8/255 has Accuracy: {acc:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TwUAmmTcl3G-",
        "6YkpcqvmTcq6",
        "ppg_6w0joa-D",
        "68Fnkb39vYnl",
        "snQvAMfH4ku1",
        "zFbxKpeM4AR9",
        "aRPjp84p81nn"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}